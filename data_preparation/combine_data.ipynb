{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c387bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2671888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AKBNK', 'ARCLK', 'ASELS', 'BIMAS', 'DOHOL', 'EKGYO', 'EREGL', 'GARAN', 'GUBRF', 'HALKB', 'ISCTR', 'KCHOL', 'KOZAA', 'KOZAL', 'KRDMD', 'MGROS', 'OYAKC', 'PETKM', 'PGSUS', 'SAHOL', 'SISE', 'TAVHL', 'TCELL', 'THYAO', 'TKFEN', 'TSKB', 'TTKOM', 'TUPRS', 'VAKBN', 'YKBNK']\n"
     ]
    }
   ],
   "source": [
    "# files will be read from data_path and will be written to data_write_path\n",
    "data_path = \"../data/2017-01-01_2020-12-28_BIST30_1min/bar/\"\n",
    "data_write_path = \"../data/1min/\"\n",
    "\n",
    "# get names of files in data_path directory\n",
    "files = os.listdir(data_path)\n",
    "\n",
    "# map stock labels and files\n",
    "stock_files = dict()\n",
    "\n",
    "for file in files:\n",
    "    stock_name = file.split(\"_\")[2]\n",
    "    if stock_name in stock_files:\n",
    "        stock_files[stock_name].append(file)\n",
    "    else:\n",
    "        stock_files[stock_name] = [file]\n",
    "\n",
    "# get stock labels seperately\n",
    "stock_labels = sorted(list(stock_files.keys()))\n",
    "\n",
    "print(stock_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7506c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_files(stock_files):\n",
    "    \"\"\"\n",
    "    Combine the data of a stock which is stored in several files. Concatenate them using\n",
    "    pandas DataFrame library.\n",
    "    \"\"\"\n",
    "    \n",
    "    for stock in stock_files.keys():\n",
    "        \n",
    "        files = sorted(stock_files[stock])  # sorted to maintain sequentiality\n",
    "        \n",
    "        # final file will be written to this path\n",
    "        combined_data_filename = data_write_path + stock + \".csv\"\n",
    "        \n",
    "        # read files and concatenate\n",
    "        df = pd.DataFrame()\n",
    "        \n",
    "        for file in files:\n",
    "            if df.empty:  # initialize if file is empty\n",
    "                df = pd.read_csv(data_path + file)\n",
    "            else:  # concatenate if file is not empty\n",
    "                df2 = pd.read_csv(data_path + file)\n",
    "                df = pd.concat([df, df2], axis=0)\n",
    "        \n",
    "        try:\n",
    "            df.to_csv(combined_data_filename)\n",
    "        except FileNotFoundError:  # if data write directory does not exist, then create it and continue\n",
    "            os.mkdir(data_write_path)\n",
    "            df.to_csv(combined_data_filename)\n",
    "        print(f\"{stock} files are combined and saved to {combined_data_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9702b181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KRDMD files are combined and saved to ../data/1min/KRDMD.csv\n",
      "GUBRF files are combined and saved to ../data/1min/GUBRF.csv\n",
      "THYAO files are combined and saved to ../data/1min/THYAO.csv\n",
      "TCELL files are combined and saved to ../data/1min/TCELL.csv\n",
      "PGSUS files are combined and saved to ../data/1min/PGSUS.csv\n",
      "DOHOL files are combined and saved to ../data/1min/DOHOL.csv\n",
      "TAVHL files are combined and saved to ../data/1min/TAVHL.csv\n",
      "TKFEN files are combined and saved to ../data/1min/TKFEN.csv\n",
      "OYAKC files are combined and saved to ../data/1min/OYAKC.csv\n",
      "TUPRS files are combined and saved to ../data/1min/TUPRS.csv\n",
      "EREGL files are combined and saved to ../data/1min/EREGL.csv\n",
      "GARAN files are combined and saved to ../data/1min/GARAN.csv\n",
      "PETKM files are combined and saved to ../data/1min/PETKM.csv\n",
      "EKGYO files are combined and saved to ../data/1min/EKGYO.csv\n",
      "BIMAS files are combined and saved to ../data/1min/BIMAS.csv\n",
      "YKBNK files are combined and saved to ../data/1min/YKBNK.csv\n",
      "ARCLK files are combined and saved to ../data/1min/ARCLK.csv\n",
      "HALKB files are combined and saved to ../data/1min/HALKB.csv\n",
      "KOZAA files are combined and saved to ../data/1min/KOZAA.csv\n",
      "ASELS files are combined and saved to ../data/1min/ASELS.csv\n",
      "SISE files are combined and saved to ../data/1min/SISE.csv\n",
      "KOZAL files are combined and saved to ../data/1min/KOZAL.csv\n",
      "TTKOM files are combined and saved to ../data/1min/TTKOM.csv\n",
      "VAKBN files are combined and saved to ../data/1min/VAKBN.csv\n",
      "KCHOL files are combined and saved to ../data/1min/KCHOL.csv\n",
      "MGROS files are combined and saved to ../data/1min/MGROS.csv\n",
      "ISCTR files are combined and saved to ../data/1min/ISCTR.csv\n",
      "AKBNK files are combined and saved to ../data/1min/AKBNK.csv\n",
      "SAHOL files are combined and saved to ../data/1min/SAHOL.csv\n",
      "TSKB files are combined and saved to ../data/1min/TSKB.csv\n"
     ]
    }
   ],
   "source": [
    "combine_files(stock_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a143faf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
